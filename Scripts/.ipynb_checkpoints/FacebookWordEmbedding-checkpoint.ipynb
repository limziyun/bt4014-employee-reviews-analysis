{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('../Dataset/employee_reviews.csv', encoding = \"ISO-8859-1\",error_bad_lines=False);\n",
    "facebook_df=data.loc[data['company']=='facebook']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_lines=facebook_df['pros'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "review_pro_lines=list()\n",
    "\n",
    "for line in pro_lines:\n",
    "    tokens=word_tokenize(line)\n",
    "    #convert lower\n",
    "    tokens=[w.lower() for w in tokens]\n",
    "    #punctuation\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    stripped=[w.translate(table) for w in tokens]\n",
    "    #remove non alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    #stop words\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    words=[w for w in words if not w in stop_words]\n",
    "    #remove short words\n",
    "    words = [word for word in words if len(word)>3]\n",
    "    review_pro_lines.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_pro_lines[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_facebook_pro = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(flatten_facebook_pro(review_pro_lines))\n",
    "print(counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model_pro=gensim.models.Word2Vec(sentences=review_pro_lines,size=100,window=5,workers=4,min_count=1,sg=1)\n",
    "\n",
    "#vocab\n",
    "words=list(model_pro.wv.vocab)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pro.wv.most_similar('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pro.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pro.wv.most_similar('culture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pro.wv.most_similar('benefits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pro.wv.most_similar('environment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_lines=facebook_df['cons'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_con_lines=list()\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "for line in con_lines:\n",
    "    tokens=word_tokenize(line)\n",
    "    #convert lower\n",
    "    tokens=[w.lower() for w in tokens]\n",
    "    #punctuation\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    stripped=[w.translate(table) for w in tokens]\n",
    "    #remove non alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    #stop words\n",
    "    words=[w for w in words if not w in stop_words]\n",
    "    review_con_lines.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_con_lines[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_facebook_con = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(flatten_facebook_con(review_con_lines))\n",
    "print(counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con=gensim.models.Word2Vec(sentences=review_con_lines,size=100,window=5,workers=4,min_count=1,sg=1)\n",
    "\n",
    "#vocab\n",
    "words=list(model_con.wv.vocab)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.wv.most_similar('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.wv.most_similar('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.wv.most_similar('company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.wv.most_similar('environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.wv.most_similar('benefits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.wv.most_similar('hard')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
